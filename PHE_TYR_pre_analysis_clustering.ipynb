{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12586775-5b94-4a14-9343-338c3e91509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib\n",
    "from scipy.optimize import curve_fit\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import griddata\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from typing import Tuple, Any\n",
    "import ipympl\n",
    "%matplotlib ipympl\n",
    "np.random.seed(23061998)\n",
    "import random\n",
    "import gzip\n",
    "RANDOM_SEED = 23061998\n",
    "\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1287c7-3f78-498b-b91f-ed126ec1c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reps(confs_df: str, res_i_name: str, n_optimal: int):\n",
    "    '''    Arguments:\n",
    "    ---\n",
    "        @ all_df: a pandas dataframe containing all conformations found in pdb for the given pair\n",
    "        @ major_df: a pandas dataframe containing screened populated categories generated by the categorized_datapoints function\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "        @ a numpy array containing indices of the representative confs for each category. Indices point to the confs\n",
    "        in all_df'''\n",
    "    gaussian = True\n",
    "    \n",
    "    all_df = pd.read_csv(confs_df, index_col=0)\n",
    "    samples = all_df.iloc[:,-4:].to_numpy() #training set is all data points in space\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(samples)\n",
    "    scaled_samples = scaler.transform(samples)\n",
    "\n",
    "    if gaussian == True:\n",
    "        optimal_gmm = GaussianMixture(n_components=n_optimal, random_state=RANDOM_SEED)\n",
    "        optimal_gmm.fit(scaled_samples)\n",
    "        labels = optimal_gmm.predict(scaled_samples)\n",
    "\n",
    "    else:\n",
    "        clustering = AgglomerativeClustering(n_clusters=n_optimal)\n",
    "        labels = clustering.fit_predict(samples)\n",
    "    # clustering.centroids\n",
    "\n",
    "    all_df['clustering_lables'] = labels\n",
    "\n",
    "    # clustering.centroids\n",
    "    nearest_centroids = NearestCentroid()\n",
    "    nearest_centroids.fit(scaled_samples, labels)\n",
    "    centroids = nearest_centroids.centroids_\n",
    "    #nearest_neightbor = NearestNeighbors(n_neighbors=1)\n",
    "    # print(centroids.shape)\n",
    "    inverse_centroid = scaler.inverse_transform(centroids)\n",
    "    # print('X')\n",
    "    #print(inverse_centroid)\n",
    "    \n",
    "    nearest_neightbor = NearestNeighbors(n_neighbors=1)\n",
    "    rep_per_label = {} #parameters in 3 coord of representors\n",
    "    rep_non_scaled = {} #indices in the all atom array\n",
    "    rep_indices = []\n",
    "    \n",
    "    for label, centorid in enumerate(centroids):\n",
    "        #print(centorid,label)\n",
    "        labels_arr = all_df['clustering_lables'].to_numpy()\n",
    "        idx = np.where(labels_arr == label)\n",
    "        idx = np.ravel(idx)\n",
    "                \n",
    "        samples_for_label = scaled_samples[idx]\n",
    "        non_scaled_samples = samples[idx]\n",
    "        #now extract the index in indices list. that's nearest group's centoid:\n",
    "        rep = nearest_neightbor.fit(samples_for_label).kneighbors(centorid.reshape(1,-1), return_distance=False)[:,0]\n",
    "        #print(rep)\n",
    "        rep_per_label[label] = samples_for_label[rep][0,:]\n",
    "        \n",
    "        rep_non_scaled[label] = non_scaled_samples[rep][0,:]\n",
    "        \n",
    "        int_rep = int(rep)\n",
    "        curr_rep = idx[int_rep]\n",
    "        rep_indices.append(curr_rep)\n",
    "\n",
    "\n",
    "    reps_arr = []\n",
    "    for key in range(len(rep_per_label)):\n",
    "        reps_arr.append(rep_per_label[key])\n",
    "    reps_arr = np.array(reps_arr)\n",
    "    \n",
    "    non_scaled_reps_arr = []\n",
    "    for key in range(len(rep_non_scaled)):\n",
    "        non_scaled_reps_arr.append(rep_non_scaled[key])\n",
    "    non_scaled_reps_arr = np.array(non_scaled_reps_arr)\n",
    "    #all members array:\n",
    "    all_df.iloc[rep_indices,:4].to_csv(f'../csv_files/TRP_{res_i_name}_rep_confs.csv')\n",
    "    \n",
    "    if not os.path.isdir(f\"../../TRP_{res_i_name}_xyz\"):\n",
    "        os.makedirs(f\"../../TRP_{res_i_name}_xyz\")\n",
    "    all_confs_df = pd.read_csv(f'../csv_files/TRP_{res_i_name}_rep_confs.csv', index_col=0)\n",
    "    for pdb_file in all_confs_df.iloc[:,0].values.tolist():\n",
    "        gzip_file = f\"../../{pdb_file}.gz\"\n",
    "        with gzip.open(gzip_file, 'rb') as f_in:\n",
    "            with open(f\"../../TRP_{res_i_name}_xyz/{pdb_file}\", 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    return centroids, reps_arr, non_scaled_reps_arr, samples, labels             \n",
    "\n",
    "def find_representative_confs(data_file: str, n_optimal: int, res_i_name) -> np.ndarray:\n",
    "    \"\"\"Finds a single closest geometry point in the space of P, D (rescaled), Ttheta1, Ttheta2.\n",
    "    The representative points should be closest to the cluster representing the (P,D,T1,T2) spatial occupancies.\n",
    "\n",
    "    Params:\n",
    "        data_file (str) - name/path of a csv datafile containing all conformations found in pdb for the given pair and their 4D params.\n",
    "        n_optimal (int) - number of clusters to assume.\n",
    "        res_i_name (str) - The first residue here is TRP, so res_i_name represents the name of the pair residue of TRP.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A numpy array containing indices of the representative confs for each category. Indices point to the confs\n",
    "        in all_df.\n",
    "    \"\"\"\n",
    "    # data_file = 'fixed_TRP_cationpi.csv'\n",
    "    centroids, reps_arr, non_scaled_reps_arr, samples, labels = extract_reps(data_file, res_i_name, n_optimal)\n",
    "    \n",
    "    return centroids, reps_arr, non_scaled_reps_arr, samples, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db4e3605-f0eb-47fb-90ab-79d0556834ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_optimal = 154\n",
    "res_j_name = 'TYR'\n",
    "data_file = f'../csv_files/TRP_{res_j_name}.csv'\n",
    "cents,reps_scaled,reps_origin,samples,labels = find_representative_confs(data_file, n_optimal, res_j_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "95294d7b3eeff144aee00fab7fd5d920cf2110b452659f9ee56ddf074e4f016c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
